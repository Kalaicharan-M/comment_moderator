# ğŸ›¡ï¸ Comment Moderator - Offline Comment Filtering using Local LLM

This project is a **comment moderation system** that detects and flags **offensive, toxic, or profane comments** from a dataset using a **local AI model**â€”no API key required.

---

## ğŸ” Features

- âœ… Detects offensive language using a pre-trained local model
- ğŸ”¥ Uses `transformers` pipeline for comment classification
- ğŸš« Flags profanity using `better_profanity`
- ğŸ“Š Generates a report and a bar chart for offense types
- ğŸ“ Supports CSV input and Excel output

---

## ğŸ§  How It Works

1. Loads comments from a CSV file
2. Analyzes each comment:
   - Checks for **profanity**
   - Uses a **local model** to classify comments as `toxic`, `hate speech`, etc.
3. Generates:
   - A CSV of flagged comments
   - A bar chart showing offense distribution

---

## ğŸ“‚ Project Structure
COMMENT_MODERATOR/ â”‚ â”œâ”€â”€ main.py # Entry point â”œâ”€â”€ comment_analyzer.py # Local classification logic â”œâ”€â”€ utils.py # Helper for plotting â”œâ”€â”€ sample_data/ â”‚ â””â”€â”€ comments.csv # Input comments â”œâ”€â”€ output/ â”‚ â”œâ”€â”€ flagged_comments.xlsx # Output flagged comments â”‚ â””â”€â”€ offense_distribution.png â”œâ”€â”€ requirements.txt â”œâ”€â”€ .env # Optional env file (not needed for local LLM) â””â”€â”€ README.md
